{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cp=sns.color_palette(\"Set2\", n_colors=72).as_hex()\n",
    "colors={\n",
    "\"RootTask\":cp[0],\n",
    "\"DistributionTask\":cp[1],\n",
    "\"TrackVeteranTask\":cp[2],\n",
    "\"HearingTask\":cp[3],\n",
    "\"ScheduleHearingTask\":cp[4],\n",
    "\"InformalHearingPresentationTask\":cp[5],\n",
    "\"BvaDispatchTask\":cp[6],\n",
    "\"EvidenceSubmissionWindowTask\":cp[7],\n",
    "\"JudgeDecisionReviewTask\":cp[8],\n",
    "\"AttorneyTask\":cp[9],\n",
    "\"JudgeAssignTask\":cp[10],\n",
    "\"HearingAdminActionVerifyAddressTask\":cp[11],\n",
    "\"AssignHearingDispositionTask\":cp[12],\n",
    "\"EvidenceOrArgumentMailTask\":cp[13],\n",
    "\"TranslationTask\":cp[14],\n",
    "\"TranscriptionTask\":cp[15],\n",
    "\"QualityReviewTask\":cp[16],\n",
    "\"OtherColocatedTask\":cp[17],\n",
    "\"AttorneyRewriteTask\":cp[18],\n",
    "\"TimedHoldTask\":cp[19],\n",
    "\"IhpColocatedTask\":cp[20],\n",
    "\"AodMotionMailTask\":cp[21],\n",
    "\"ScheduleHearingColocatedTask\":cp[22],\n",
    "\"VeteranRecordRequest\":cp[23],\n",
    "\"HearingRelatedMailTask\":cp[24],\n",
    "\"JudgeDispatchReturnTask\":cp[25],\n",
    "\"MissingRecordsColocatedTask\":cp[26],\n",
    "\"ReturnedUndeliverableCorrespondenceMailTask\":cp[27],\n",
    "\"NoShowHearingTask\":cp[28],\n",
    "\"GenericTask\":cp[29],\n",
    "\"StayedAppealColocatedTask\":cp[30],\n",
    "\"ExtensionRequestMailTask\":cp[31],\n",
    "\"ExtensionColocatedTask\":cp[32],\n",
    "\"FoiaTask\":cp[33],\n",
    "\"PowerOfAttorneyRelatedMailTask\":cp[34],\n",
    "\"HearingAdminActionOtherTask\":cp[35],\n",
    "\"HearingClarificationColocatedTask\":cp[36],\n",
    "\"FoiaColocatedTask\":cp[37],\n",
    "\"StatusInquiryMailTask\":cp[38],\n",
    "\"PoaClarificationColocatedTask\":cp[39],\n",
    "\"HearingAdminActionForeignVeteranCaseTask\":cp[40],\n",
    "\"PreRoutingFoiaColocatedTask\":cp[41],\n",
    "\"JudgeQualityReviewTask\":cp[42],\n",
    "\"CongressionalInterestMailTask\":cp[43],\n",
    "\"SpecialCaseMovementTask\":cp[44],\n",
    "\"PrivacyActTask\":cp[45],\n",
    "\"ChangeHearingDispositionTask\":cp[46],\n",
    "\"AddressChangeMailTask\":cp[47],\n",
    "\"VacateMotionMailTask\":cp[48],\n",
    "\"PreRoutingTranslationColocatedTask\":cp[49],\n",
    "\"FoiaRequestMailTask\":cp[50],\n",
    "\"AttorneyDispatchReturnTask\":cp[51],\n",
    "\"AttorneyQualityReviewTask\":cp[52],\n",
    "\"ReconsiderationMotionMailTask\":cp[53],\n",
    "\"PrivacyActRequestMailTask\":cp[54],\n",
    "\"DeathCertificateMailTask\":cp[55],\n",
    "\"AojColocatedTask\":cp[56],\n",
    "\"AddressVerificationColocatedTask\":cp[57],\n",
    "\"TranslationColocatedTask\":cp[58],\n",
    "\"Task\":cp[59],\n",
    "\"BoardGrantEffectuationTask\":cp[60],\n",
    "\"AppealWithdrawalMailTask\":cp[61],\n",
    "\"PendingScanningVbmsColocatedTask\":cp[62],\n",
    "\"OtherMotionMailTask\":cp[63],\n",
    "\"ControlledCorrespondenceMailTask\":cp[64],\n",
    "\"UnaccreditedRepColocatedTask\":cp[65],\n",
    "\"PulacCerulloTask\":cp[66],\n",
    "\"PreRoutingMissingHearingTranscriptsColocatedTask\":cp[67],\n",
    "\"NewRepArgumentsColocatedTask\":cp[68],\n",
    "\"MissingHearingTranscriptsColocatedTask\":cp[69],\n",
    "\"HearingAdminActionFoiaPrivacyRequestTask\":cp[70]\n",
    "}\n",
    "customcolors={\n",
    "\"assigned\":\"#cc6600\",\n",
    "\"inprogress\":\"#006600\",\n",
    "\"completed\":\"#0000cc\",\n",
    "}\n",
    "colors.update(customcolors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejectCancelled(data):\n",
    "    return [t for t in data['tasks'] if not t['status']==\"cancelled\"]\n",
    "\n",
    "def typesToStringUpTo(i, tcs):\n",
    "    return \".\".join(tcs[0:i+1])\n",
    "\n",
    "appealIdsLimit=5\n",
    "appealIdsDict={}\n",
    "tcsCountsDict={}\n",
    "tcsSetDict={}\n",
    "nextlinksDict={}\n",
    "backlinksDict={}\n",
    "\n",
    "def flatten(data):\n",
    "    taskscreationseq=list(map(lambda task: task['type']+\"_\"+task['assigned_to_type'], rejectCancelled(data)))\n",
    "    for i in range(len(taskscreationseq)):\n",
    "        task=taskscreationseq[i]\n",
    "        if i>0:\n",
    "            backlinksDict[task]=backlinksDict.get(task, {})\n",
    "            backlinksDict[task][taskscreationseq[i-1]]=backlinksDict[task].get(taskscreationseq[i-1], 0)+1\n",
    "        if i+1<len(taskscreationseq):\n",
    "            nextlinksDict[task]=nextlinksDict.get(task, {})\n",
    "            nextlinksDict[task][taskscreationseq[i+1]]=nextlinksDict[task].get(taskscreationseq[i+1], 0)+1\n",
    "        \n",
    "        typePrefix=typesToStringUpTo(i, taskscreationseq)\n",
    "        \n",
    "        tcsSetDict[task]=tcsSetDict.get(task, set())\n",
    "        tcsSetDict[task].add(typePrefix)\n",
    "        \n",
    "        tcsCountsDict[typePrefix]=tcsCountsDict.get(typePrefix,0)+1\n",
    "        \n",
    "        appealIdsDict[typePrefix]=appealIdsDict.get(typePrefix, [])\n",
    "        if(len(appealIdsDict[typePrefix])<appealIdsLimit):\n",
    "            appealIdsDict[typePrefix].append(data['appeal_id'])\n",
    "            \n",
    "        #print(i, tcsCountsDict[typePrefix], appealIdsDict[typePrefix], tcsSetDict[tcs], typePrefix)\n",
    "    #del data['tasks']\n",
    "    #return { 'docket': data['docket_type'], 'tcs': taskscreationseq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearData():\n",
    "    appealIdsDict.clear()\n",
    "    tcsCountsDict.clear()\n",
    "    tcsSetDict.clear()\n",
    "    nextlinksDict.clear()\n",
    "    backlinksDict.clear()\n",
    "\n",
    "def loadData(inputfile, dockettype):\n",
    "    clearData()\n",
    "    #with open('prepped2.json', 'w') as pf:\n",
    "    with open(inputfile) as jf:\n",
    "        for count, line in enumerate(jf):\n",
    "            data = json.loads(line)\n",
    "            #removeExtraFields(data)\n",
    "            if data['docket_type']==dockettype:\n",
    "                flatdata=flatten(data)\n",
    "            #print(count, data['appeal_id'], flatdata)\n",
    "            #pf.write(json.dumps(flatdata)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tasklist(basedir):\n",
    "    with open(f'{basedir}/tasklist.md', 'w') as tlf:\n",
    "        tlf.write(f'# Task Listing for \"{dockettype}\" Docket\\n\\n')\n",
    "        listing={}\n",
    "        for taskname,tcsSet in tcsSetDict.items():\n",
    "            count=sum([tcsCountsDict[tcs] for tcs in tcsSet])\n",
    "            listing[taskname]=count\n",
    "        for taskname,count in sorted(listing.items(), key=lambda kv: kv[1], reverse=True):\n",
    "            tlf.write(f'   * [{taskname}]({taskname}.md) ({count} occurrences)\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(appealIdsDict)            \n",
    "print(tcsCountsDict)\n",
    "print(tcsSetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph G {\n",
      "rankdir=\"LR\";\n",
      "\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def gen_graphviz(nextlinksDict, backlinksDict, *tasknames):\n",
    "    edges=set()\n",
    "    for taskname in tasknames:\n",
    "        if taskname in nextlinksDict:\n",
    "            for link,count in sorted(nextlinksDict[taskname].items(), key=lambda kv: kv[1], reverse=True):\n",
    "                edges.add(f'\"{taskname}\" -> \"{link}\" [label={count}]')\n",
    "        if taskname in backlinksDict:\n",
    "            for link,count in sorted(backlinksDict[taskname].items(), key=lambda kv: kv[1], reverse=True):\n",
    "                edges.add(f'\"{link}\" -> \"{taskname}\" [label={count}]')\n",
    "    gstr='digraph G {\\nrankdir=\"LR\";\\n'\n",
    "    gstr+=\"\\n\".join(edges)\n",
    "    gstr+=\"\\n}\\n\"\n",
    "    return gstr\n",
    "\n",
    "def save_graphviz(basedir, nextlinksDict, backlinksDict, *tasknames):\n",
    "    tcsName=abbrev(\".\".join(tasknames))\n",
    "    with open(f'{basedir}/dot/{tcsName}.dot', 'w') as gvf:\n",
    "        gvf.write(gen_graphviz(nextlinksDict, backlinksDict, *tasknames))\n",
    "\n",
    "print(gen_graphviz(nextlinksDict, backlinksDict, \"RootTask_Organization\", \"DistributionTask_Organization\", \"EvidenceSubmissionWindowTask_Organization\"))\n",
    "save_graphviz(basedir, nextlinksDict, backlinksDict, \"RootTask_Organization\", \"DistributionTask_Organization\", \"EvidenceSubmissionWindowTask_Organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True {'appeal_id': 41852, 'docket_type': 'direct_review', 'updated_at': '2019-11-13 19:13:22 UTC', 'tasks': [{'id': 514013, 'status': 'cancelled', 'type': 'RootTask', 'created_at': '2019-11-12T17:14:08.206Z', 'updated_at': '2019-11-12T17:14:08.877Z', 'assigned_to_type': 'Organization', 'parent_id': None}, {'id': 514014, 'status': 'completed', 'type': 'DistributionTask', 'created_at': '2019-11-12T17:14:08.873Z', 'updated_at': '2019-11-12T18:23:27.474Z', 'assigned_to_type': 'Organization', 'parent_id': 514013}, {'id': 514187, 'status': 'cancelled', 'type': 'JudgeAssignTask', 'created_at': '2019-11-12T18:23:27.463Z', 'updated_at': '2019-11-12T18:23:27.463Z', 'assigned_to_type': 'User', 'parent_id': 514013}]}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "def find_appeal(inputfile, appeal_id):\n",
    "    with open(inputfile, \"r\") as f:\n",
    "        for count, line in enumerate(f):\n",
    "            if re.search(f\"\\\"appeal_id\\\":{appeal_id},\", line):\n",
    "                data = json.loads(line)\n",
    "                return data\n",
    "            \n",
    "appeal_id=\"41852\"\n",
    "appeal=find_appeal(\"input2.json\", appeal_id)\n",
    "print(appeal['appeal_id']==int(appeal_id), appeal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@startuml\n",
      "skinparam {\n",
      "  ObjectBorderColor #555\n",
      "  ObjectBorderThickness 0\n",
      "  ObjectFontStyle bold\n",
      "  ObjectFontSize 14\n",
      "  ObjectAttributeFontColor #333\n",
      "  ObjectAttributeFontSize 12\n",
      "}\n",
      "  object 0.RootTask #66c2a5 {\n",
      "Organization\n",
      "}\n",
      "  object 1.DistributionTask #fc8d62 {\n",
      "Organization  <back:white>    </back>\n",
      "}\n",
      "  object 2.JudgeAssignTask #8da0cb {\n",
      "User\n",
      "}\n",
      "0.RootTask -- 1.DistributionTask\n",
      "0.RootTask -- 2.JudgeAssignTask\n",
      "@enduml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def gen_plantuml(appeal, highlighttype=\"\", limit=200):\n",
    "    pstr = \"\"\"@startuml\n",
    "skinparam {\n",
    "  ObjectBorderColor #555\n",
    "  ObjectBorderThickness 0\n",
    "  ObjectFontStyle bold\n",
    "  ObjectFontSize 14\n",
    "  ObjectAttributeFontColor #333\n",
    "  ObjectAttributeFontSize 12\n",
    "}\n",
    "\"\"\"\n",
    "    taskId2LabelDict={}\n",
    "    for task in appeal['tasks']:\n",
    "        taskLabel=f\"{len(taskId2LabelDict)}.{task['type']}\"\n",
    "        taskId2LabelDict[task['id']]=taskLabel\n",
    "        pstr+=f\"  object {taskLabel} {colors[task['type']]}\"\n",
    "        pstr+=\" {\\n\"\n",
    "        pstr+=task['assigned_to_type']\n",
    "        if task['type']+\"_\"+task['assigned_to_type']==highlighttype:\n",
    "            pstr+=f\"  <back:white>    </back>\"\n",
    "        pstr+=\"\\n}\\n\"\n",
    "    for task in appeal['tasks']:\n",
    "        if task['parent_id']:\n",
    "            pstr+=f\"{taskId2LabelDict.get(task['parent_id'])} -- {taskId2LabelDict[task['id']]}\\n\"\n",
    "    pstr+=\"@enduml\\n\"\n",
    "    return pstr\n",
    "\n",
    "print(gen_plantuml(appeal, \"DistributionTask_Organization\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbrev(tcs):\n",
    "    return ''.join(filter(lambda x: x.isupper() or x=='.', str(tcs)))\n",
    "\n",
    "def gen_md_files(inputfile, basedir):\n",
    "    for taskname,tcsSet in tcsSetDict.items():\n",
    "        #print(task, tcsSet)\n",
    "        with open(f'{basedir}/{taskname}.md', 'w') as mdf:\n",
    "            #mdf.write('# '+taskname.split(\"_\")[0]+\" \"+taskname.split(\"_\")[1]+'\\n\\n')\n",
    "            mdf.write('| [README.md](/README.md) | [Task Listing](tasklist.md) |\\n\\n')\n",
    "            mdf.write(f'# {taskname}\\n\\n')\n",
    "            mdf.write(f'## Tasks Created Before and After\\n\\n')\n",
    "            mdf.write(f\"<details><summary>Tasks created before and after {taskname}</summary>\\n\\n```\\n\")\n",
    "            graphviz=gen_graphviz(nextlinksDict, backlinksDict, taskname)\n",
    "            mdf.write(graphviz)\n",
    "            mdf.write('```\\n</details>\\n\\n')\n",
    "            mdf.write(f'![{taskname}](dot/{taskname}.dot.png)\\n\\n')\n",
    "            with open(f'{basedir}/dot/{taskname}.dot', 'w') as gvf:\n",
    "                gvf.write(graphviz)\n",
    "\n",
    "            mdf.write('**Before:**\\n\\n')\n",
    "            if taskname in backlinksDict:\n",
    "                for link,count in sorted(backlinksDict[taskname].items(), key=lambda kv: kv[1], reverse=True):\n",
    "                    mdf.write(f\"   * [{link}]({link}.md): {count} times\\n\")\n",
    "            mdf.write(\"\\n\")\n",
    "            mdf.write('**After:**\\n\\n')\n",
    "            if taskname in nextlinksDict:\n",
    "                for link,count in sorted(nextlinksDict[taskname].items(), key=lambda kv: kv[1], reverse=True):\n",
    "                    mdf.write(f\"   * [{link}]({link}.md): {count} times\\n\")\n",
    "            mdf.write(\"\\n\")\n",
    "\n",
    "            mdf.write('## Task Creation Sequences\\n\\n')\n",
    "            for tcs in sorted(tcsSet, key=lambda k: tcsCountsDict[k], reverse=True):\n",
    "                mdf.write(gen_tcs_section(inputfile, basedir, taskname, tcs, tcsCountsDict[tcs], appealIdsDict[tcs]))\n",
    "\n",
    "def gen_tcs_section(inputfile, basedir, taskname, tcs, count, example_appeal_ids):\n",
    "    tcsName=abbrev(tcs)\n",
    "    tstr=f\"### {tcsName}\\n\\n\"\n",
    "    tstr+=f\"{count} occurrences (example appeal IDs: {example_appeal_ids})\\n\\n\"\n",
    "    appealId=appealIdsDict[tcs][0]\n",
    "    tstr+=f\"<details><summary>Task Tree for appeal with ID {appealId}</summary>\\n\\n```\\n\"\n",
    "    appeal=find_appeal(inputfile, appealId)\n",
    "    plantuml=gen_plantuml(appeal, taskname)\n",
    "    tstr+=plantuml\n",
    "    tstr+='```\\n</details>\\n\\n'\n",
    "    \n",
    "    tstr+=f'![{tcsName}-{appealId}](uml/{tcsName}-{appealId}.png)\\n\\n'\n",
    "    # create associated plantUML file to generate png\n",
    "    with open(f'{basedir}/uml/{tcsName}-{appealId}.uml', 'w') as umlf:\n",
    "        umlf.write(plantuml)\n",
    "        \n",
    "    return tstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'input2.json' 'input-all.json'\n",
    "inputfile='input2.json' #'input-all.json'\n",
    "\n",
    "dockettypes={ \"direct_review\":\"docs-DR\", \"evidence_submission\":\"docs-ES\", \"hearing\":\"docs-H\" }\n",
    "for dockettype,basedir in dockettypes.items():\n",
    "    loadData(inputfile, dockettype)\n",
    "\n",
    "    import os\n",
    "    os.path.isdir(basedir) or os.mkdir(basedir)\n",
    "    os.path.isdir(basedir+'/uml') or os.mkdir(basedir+'/uml')\n",
    "    os.path.isdir(basedir+'/dot') or os.mkdir(basedir+'/dot')\n",
    "\n",
    "    create_tasklist(basedir)\n",
    "    gen_md_files(inputfile, basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcsSetDict['DistributionTask_Organization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.search(\"[A-Z]\",\"RootTask_Organization.TrackVeteranTask_Organization.n\"))\n",
    "print(dir(\"\"))\n",
    "print(str(['a', 'b']))\n",
    "print(abbrev(\"RootTask_Organization.TrackVeteranTask_Organization.n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typenames={}\n",
    "with open('input-all.json') as jf:\n",
    "    for count, line in enumerate(jf):\n",
    "        line = jf.readline()\n",
    "        data = json.loads(line)\n",
    "        for t in data['tasks']:\n",
    "            count=typenames.get(t['type'],0)\n",
    "            typenames[t['type']]=count+1\n",
    "\n",
    "sortednames=sorted(typenames.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "sortednames.reverse()\n",
    "i=0\n",
    "for name,count in sortednames:\n",
    "    print(\"\\\"\"+name+\"\\\":cp[\"+str(i)+\"],\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"Set2\", n_colors=72).as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,color in colors.items():\n",
    "    print(\"object \"+key+\" \"+color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
